{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "msg = pd.read_csv(\"spam-msg.txt\", sep = \"\\t\", names=[\"label\", \"msg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  label                                                msg\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "print(msg.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for index,row in msg.iterrows():\n",
    "    dataset.append((row['msg'], row['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5572\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess(document, stem=True):\n",
    "\n",
    "    # change sentence to lower case\n",
    "    document = document.lower()\n",
    "\n",
    "    # tokenize into words\n",
    "    words = word_tokenize(document)\n",
    "\n",
    "    # remove stop words\n",
    "    words = [word for word in words if word not in stopwords.words(\"english\")]\n",
    "\n",
    "    if stem:\n",
    "        words = [stemmer.stem(word) for word in words]\n",
    "    else:\n",
    "        words = [wordnet_lemmatizer.lemmatize(word, pos='v') for word in words]\n",
    "\n",
    "    # join words to make sentence\n",
    "    document = \" \".join(words)\n",
    "\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_set = []\n",
    "for (msg, label) in dataset:\n",
    "    words_filtered = [e.lower() for e in preprocess(msg, stem=False).split() if len(e) >= 3]\n",
    "    msg_set.append((words_filtered, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['jurong', 'point', 'crazy', 'available', 'bugis', 'great', 'world', 'buffet', '...', 'cine', 'get', 'amore', 'wat', '...'], 'ham'), (['lar', '...', 'joke', 'wif', 'oni', '...'], 'ham'), (['free', 'entry', 'wkly', 'comp', 'win', 'cup', 'final', 'tkts', '21st', 'may', '2005.', 'text', '87121', 'receive', 'entry', 'question', 'std', 'txt', 'rate', 'apply', '08452810075over18'], 'spam'), (['dun', 'say', 'early', 'hor', '...', 'already', 'say', '...'], 'ham'), (['nah', \"n't\", 'think', 'usf', 'live', 'around', 'though'], 'ham'), (['freemsg', 'hey', 'darling', 'week', 'word', 'back', 'like', 'fun', 'still', 'xxx', 'std', 'chgs', 'send', '£1.50', 'rcv'], 'spam'), (['even', 'brother', 'like', 'speak', 'treat', 'like', 'aid', 'patent'], 'ham'), (['per', 'request', \"'melle\", 'melle', 'oru', 'minnaminunginte', 'nurungu', 'vettam', 'set', 'callertune', 'callers', 'press', 'copy', 'friends', 'callertune'], 'ham'), (['winner', 'value', 'network', 'customer', 'select', 'receivea', '£900', 'prize', 'reward', 'claim', 'call', '09061701461.', 'claim', 'code', 'kl341', 'valid', 'hours'], 'spam'), (['mobile', 'months', 'entitle', 'update', 'latest', 'colour', 'mobiles', 'camera', 'free', 'call', 'mobile', 'update', 'free', '08002986030'], 'spam')]\n"
     ]
    }
   ],
   "source": [
    "print(msg_set[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(msg):\n",
    "    all_words = []\n",
    "    for (msg, label) in msg:\n",
    "      all_words.extend(msg)\n",
    "    return all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_features(wordlist):\n",
    "\n",
    "    wordlist = nltk.FreqDist(wordlist)\n",
    "    word_features = wordlist.keys()\n",
    "    return word_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7995\n"
     ]
    }
   ],
   "source": [
    "word_features = get_word_features(get_words(msg_set))\n",
    "print(len(word_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = int((len(msg_set)*.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(msg_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = msg_set[:size], msg_set[size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)\n",
    "len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains(%s)' % word] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = nltk.classify.apply_features(extract_features, train_set)\n",
    "testing_set = nltk.classify.apply_features(extract_features, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4457\n",
      "1115\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(training_set))\n",
    "print(len(testing_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "spamClassifier = nltk.NaiveBayesClassifier.train(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9916984518734575\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(spamClassifier, training_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9856502242152466\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(spamClassifier, testing_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification result :  ham\n"
     ]
    }
   ],
   "source": [
    "my_msg = 'My name is Ahmed, how can I buy your python course?'\n",
    "print('Classification result : ', spamClassifier.classify(extract_features(my_msg.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification result :  spam\n"
     ]
    }
   ],
   "source": [
    "my_msg = 'CONGRATULATIONS!! As a valued account holder you have been selected to receive a £900 prize reward! Valid 12 hours only.'\n",
    "print('Classification result : ', spamClassifier.classify(extract_features(my_msg.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "       contains(service) = True             spam : ham    =    248.0 : 1.0\n",
      "         contains(award) = True             spam : ham    =    192.9 : 1.0\n",
      "         contains(await) = True             spam : ham    =    108.1 : 1.0\n",
      "        contains(urgent) = True             spam : ham    =     89.9 : 1.0\n",
      "           contains(txt) = True             spam : ham    =     80.0 : 1.0\n",
      "      contains(delivery) = True             spam : ham    =     74.2 : 1.0\n",
      "      contains(landline) = True             spam : ham    =     72.5 : 1.0\n",
      "        contains(latest) = True             spam : ham    =     72.5 : 1.0\n",
      "         contains(nokia) = True             spam : ham    =     71.8 : 1.0\n",
      "       contains(private) = True             spam : ham    =     65.7 : 1.0\n",
      "          contains(draw) = True             spam : ham    =     60.9 : 1.0\n",
      "     contains(statement) = True             spam : ham    =     57.2 : 1.0\n",
      "        contains(camera) = True             spam : ham    =     54.7 : 1.0\n",
      "          contains(club) = True             spam : ham    =     53.0 : 1.0\n",
      "          contains(info) = True             spam : ham    =     53.0 : 1.0\n",
      "          contains(quiz) = True             spam : ham    =     53.0 : 1.0\n",
      "       contains(voucher) = True             spam : ham    =     53.0 : 1.0\n",
      "          contains(rate) = True             spam : ham    =     52.1 : 1.0\n",
      "           contains(box) = True             spam : ham    =     51.8 : 1.0\n",
      "contains(congratulations) = True             spam : ham    =     48.7 : 1.0\n",
      "        contains(reveal) = True             spam : ham    =     48.7 : 1.0\n",
      "        contains(mobile) = True             spam : ham    =     47.3 : 1.0\n",
      "          contains(comp) = True             spam : ham    =     44.5 : 1.0\n",
      "           contains(mat) = True             spam : ham    =     44.5 : 1.0\n",
      "           contains(opt) = True             spam : ham    =     44.5 : 1.0\n",
      "        contains(player) = True             spam : ham    =     44.5 : 1.0\n",
      "      contains(customer) = True             spam : ham    =     44.5 : 1.0\n",
      "          contains(land) = True             spam : ham    =     42.0 : 1.0\n",
      "       contains(attempt) = True             spam : ham    =     39.4 : 1.0\n",
      "        contains(orange) = True             spam : ham    =     39.1 : 1.0\n",
      "        contains(direct) = True             spam : ham    =     36.0 : 1.0\n",
      "       contains(england) = True             spam : ham    =     36.0 : 1.0\n",
      "        contains(txting) = True             spam : ham    =     36.0 : 1.0\n",
      "          contains(user) = True             spam : ham    =     36.0 : 1.0\n",
      "         contains(apply) = True             spam : ham    =     34.6 : 1.0\n",
      "        contains(caller) = True             spam : ham    =     31.8 : 1.0\n",
      "           contains(del) = True             spam : ham    =     31.8 : 1.0\n",
      "         contains(final) = True             spam : ham    =     31.8 : 1.0\n",
      "        contains(reward) = True             spam : ham    =     31.8 : 1.0\n",
      "      contains(sunshine) = True             spam : ham    =     31.8 : 1.0\n",
      "       contains(network) = True             spam : ham    =     31.8 : 1.0\n",
      "         contains(offer) = True             spam : ham    =     30.6 : 1.0\n",
      "         contains(pound) = True             spam : ham    =     30.0 : 1.0\n",
      "       contains(contact) = True             spam : ham    =     27.9 : 1.0\n",
      "          contains(mins) = True             spam : ham    =     27.9 : 1.0\n",
      "       contains(receive) = True             spam : ham    =     27.9 : 1.0\n",
      "      contains(motorola) = True             spam : ham    =     26.7 : 1.0\n",
      "         contains(music) = True             spam : ham    =     24.5 : 1.0\n",
      "          contains(cash) = True             spam : ham    =     24.1 : 1.0\n",
      "        contains(select) = True             spam : ham    =     23.7 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(spamClassifier.show_most_informative_features(50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
